"""
LangGraph ReAct Shellæ‰§è¡Œå™¨ - ç»“åˆç¬¬ä¸‰æ–¹API (ä¿®å¤ç‰ˆ)
æ”¯æŒæ¨ç†ã€è¡ŒåŠ¨ã€è§‚å¯Ÿå¾ªç¯ï¼Œæ‰§è¡Œshellå‘½ä»¤å’ŒAPIè°ƒç”¨
"""

import json
import subprocess
import requests
from typing import Dict, Any, List, Optional, Literal, TypedDict
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage, BaseMessage
from langchain_core.tools import tool
from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, END
from langgraph.prebuilt import ToolExecutor
import os
from datetime import datetime

# é…ç½®
OPENAI_API_KEY = "your-openai-api-key"  # è¯·æ›¿æ¢ä¸ºæ‚¨çš„APIå¯†é’¥
WEATHER_API_KEY = "your-weather-api-key"  # è¯·æ›¿æ¢ä¸ºæ‚¨çš„å¤©æ°”APIå¯†é’¥

# å®šä¹‰çŠ¶æ€ç±»å‹
class AgentState(TypedDict):
    messages: List[BaseMessage]
    current_step: int
    max_steps: int
    task_completed: bool
    shell_history: List[Dict[str, str]]
    api_calls: List[Dict[str, Any]]

# å·¥å…·å®šä¹‰
@tool
def execute_shell_command(command: str) -> str:
    """
    æ‰§è¡Œshellå‘½ä»¤
    
    Args:
        command: è¦æ‰§è¡Œçš„shellå‘½ä»¤
    
    Returns:
        å‘½ä»¤æ‰§è¡Œç»“æœ
    """
    try:
        # å®‰å…¨æ£€æŸ¥ - é¿å…å±é™©å‘½ä»¤
        dangerous_commands = ['rm -rf', 'sudo rm', 'chmod +x', 'wget', 'curl -X DELETE', 'dd if=']
        if any(dangerous in command.lower() for dangerous in dangerous_commands):
            return f"é”™è¯¯: å‘½ä»¤ '{command}' è¢«å®‰å…¨ç­–ç•¥é˜»æ­¢"
        
        result = subprocess.run(
            command,
            shell=True,
            capture_output=True,
            text=True,
            timeout=30
        )
        
        output = f"é€€å‡ºç : {result.returncode}\n"
        if result.stdout:
            output += f"æ ‡å‡†è¾“å‡º:\n{result.stdout}\n"
        if result.stderr:
            output += f"æ ‡å‡†é”™è¯¯:\n{result.stderr}\n"
        
        return output
    
    except subprocess.TimeoutExpired:
        return f"é”™è¯¯: å‘½ä»¤æ‰§è¡Œè¶…æ—¶ (30ç§’)"
    except Exception as e:
        return f"é”™è¯¯: {str(e)}"

@tool
def get_weather_info(city: str) -> str:
    """
    è·å–å¤©æ°”ä¿¡æ¯
    
    Args:
        city: åŸå¸‚åç§°
    
    Returns:
        å¤©æ°”ä¿¡æ¯JSONå­—ç¬¦ä¸²
    """
    try:
        # æ¨¡æ‹Ÿå¤©æ°”APIè°ƒç”¨ï¼ˆå› ä¸ºéœ€è¦çœŸå®APIå¯†é’¥ï¼‰
        # å®é™…ä½¿ç”¨æ—¶è¯·æ›¿æ¢ä¸ºçœŸå®çš„APIè°ƒç”¨
        weather_data = {
            'city': city,
            'temperature': 25.5,
            'description': 'æ™´å¤©',
            'humidity': 60,
            'pressure': 1013
        }
        return json.dumps(weather_data, ensure_ascii=False, indent=2)
    
    except Exception as e:
        return f"é”™è¯¯: {str(e)}"

@tool
def search_github_repos(query: str) -> str:
    """
    æœç´¢GitHubä»“åº“
    
    Args:
        query: æœç´¢å…³é”®è¯
    
    Returns:
        æœç´¢ç»“æœJSONå­—ç¬¦ä¸²
    """
    try:
        url = "https://api.github.com/search/repositories"
        params = {
            'q': query,
            'sort': 'stars',
            'order': 'desc',
            'per_page': 5
        }
        
        headers = {
            'Accept': 'application/vnd.github.v3+json',
            'User-Agent': 'LangGraph-ReAct-Agent'
        }
        
        response = requests.get(url, params=params, headers=headers, timeout=10)
        
        if response.status_code == 200:
            data = response.json()
            repos = []
            for item in data['items']:
                repos.append({
                    'name': item['name'],
                    'full_name': item['full_name'],
                    'description': item['description'],
                    'stars': item['stargazers_count'],
                    'language': item['language'],
                    'url': item['html_url']
                })
            return json.dumps(repos, ensure_ascii=False, indent=2)
        else:
            return f"é”™è¯¯: æœç´¢å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}"
    
    except Exception as e:
        return f"é”™è¯¯: {str(e)}"

@tool
def get_system_info() -> str:
    """
    è·å–ç³»ç»Ÿä¿¡æ¯
    
    Returns:
        ç³»ç»Ÿä¿¡æ¯å­—ç¬¦ä¸²
    """
    try:
        import platform
        
        info = {
            'system': platform.system(),
            'node': platform.node(),
            'release': platform.release(),
            'version': platform.version(),
            'machine': platform.machine(),
            'processor': platform.processor(),
            'python_version': platform.python_version()
        }
        
        return json.dumps(info, ensure_ascii=False, indent=2)
    
    except Exception as e:
        return f"é”™è¯¯: {str(e)}"

# å®šä¹‰æ‰€æœ‰å·¥å…·
tools = [execute_shell_command, get_weather_info, search_github_repos, get_system_info]

class ReActShellAgent:
    """ReAct Shellæ‰§è¡Œä»£ç†"""
    
    def __init__(self, model_name: str = "gpt-3.5-turbo"):
        self.llm = ChatOpenAI(
            model=model_name,
            temperature=0.1,
            openai_api_key=OPENAI_API_KEY
        )
        self.tools = tools
        self.tool_executor = ToolExecutor(tools)
        self.graph = self._create_graph()
    
    def _create_graph(self) -> StateGraph:
        """åˆ›å»ºLangGraphå·¥ä½œæµ"""
        workflow = StateGraph(AgentState)
        
        # æ·»åŠ èŠ‚ç‚¹
        workflow.add_node("agent", self._agent_node)
        workflow.add_node("action", self._action_node)
        
        # è®¾ç½®å…¥å£ç‚¹
        workflow.set_entry_point("agent")
        
        # æ·»åŠ æ¡ä»¶è¾¹
        workflow.add_conditional_edges(
            "agent",
            self._should_continue,
            {
                "continue": "action",
                "end": END
            }
        )
        
        # ä»actionå›åˆ°agent
        workflow.add_edge("action", "agent")
        
        return workflow.compile()
    
    def _agent_node(self, state: AgentState) -> Dict[str, Any]:
        """Agentæ¨ç†èŠ‚ç‚¹"""
        print(f"\n=== Agentæ¨ç† (æ­¥éª¤ {state['current_step']}) ===")
        
        # æ„å»ºç³»ç»Ÿæ¶ˆæ¯
        system_msg = SystemMessage(content="""ä½ æ˜¯ä¸€ä¸ªèƒ½å¤Ÿæ‰§è¡Œshellå‘½ä»¤å’Œè°ƒç”¨APIçš„æ™ºèƒ½åŠ©æ‰‹ã€‚

å¯ç”¨å·¥å…·:
- execute_shell_command: æ‰§è¡Œshellå‘½ä»¤
- get_weather_info: è·å–å¤©æ°”ä¿¡æ¯  
- search_github_repos: æœç´¢GitHubä»“åº“
- get_system_info: è·å–ç³»ç»Ÿä¿¡æ¯

è¯·æŒ‰ReActæ¨¡å¼å·¥ä½œ:
1. æ€è€ƒå½“å‰éœ€è¦åšä»€ä¹ˆ
2. å†³å®šè°ƒç”¨å“ªä¸ªå·¥å…·
3. å¦‚æœä»»åŠ¡å®Œæˆï¼Œå›å¤"FINISHED: [æ€»ç»“]"

è¯·ç›´æ¥è°ƒç”¨å·¥å…·ï¼Œä¸è¦ç”¨JSONæ ¼å¼å›å¤ã€‚""")
        
        # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
        messages = [system_msg] + state["messages"]
        
        # è°ƒç”¨LLM
        response = self.llm.bind_tools(self.tools).invoke(messages)
        
        print(f"Agentå›å¤: {response.content}")
        
        # æ›´æ–°çŠ¶æ€
        new_state = state.copy()
        new_state["messages"] = state["messages"] + [response]
        new_state["current_step"] = state["current_step"] + 1
        
        return new_state
    
    def _action_node(self, state: AgentState) -> Dict[str, Any]:
        """å·¥å…·æ‰§è¡ŒèŠ‚ç‚¹"""
        print(f"\n=== æ‰§è¡Œå·¥å…· ===")
        
        # è·å–æœ€åä¸€æ¡æ¶ˆæ¯
        last_message = state["messages"][-1]
        
        # æ‰§è¡Œå·¥å…·è°ƒç”¨
        tool_outputs = []
        if hasattr(last_message, 'tool_calls') and last_message.tool_calls:
            for tool_call in last_message.tool_calls:
                print(f"è°ƒç”¨å·¥å…·: {tool_call['name']}")
                print(f"å‚æ•°: {tool_call['args']}")
                
                # æ‰§è¡Œå·¥å…·
                tool_output = self.tool_executor.invoke(tool_call)
                tool_outputs.append(tool_output)
                
                print(f"å·¥å…·è¾“å‡º: {tool_output.content[:200]}...")
                
                # è®°å½•å†å²
                if tool_call['name'] == 'execute_shell_command':
                    state["shell_history"].append({
                        'command': tool_call['args'].get('command', ''),
                        'result': tool_output.content,
                        'timestamp': datetime.now().isoformat()
                    })
                else:
                    state["api_calls"].append({
                        'tool': tool_call['name'],
                        'input': tool_call['args'],
                        'result': tool_output.content,
                        'timestamp': datetime.now().isoformat()
                    })
        
        # æ›´æ–°çŠ¶æ€
        new_state = state.copy()
        new_state["messages"] = state["messages"] + tool_outputs
        
        return new_state
    
    def _should_continue(self, state: AgentState) -> Literal["continue", "end"]:
        """åˆ¤æ–­æ˜¯å¦ç»§ç»­æ‰§è¡Œ"""
        last_message = state["messages"][-1]
        
        # æ£€æŸ¥æ˜¯å¦å®Œæˆ
        if hasattr(last_message, 'content') and last_message.content:
            if "FINISHED:" in last_message.content:
                print("ä»»åŠ¡å®Œæˆï¼")
                return "end"
        
        # æ£€æŸ¥æ­¥æ•°é™åˆ¶
        if state["current_step"] >= state["max_steps"]:
            print(f"è¾¾åˆ°æœ€å¤§æ­¥æ•°é™åˆ¶: {state['max_steps']}")
            return "end"
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
        if hasattr(last_message, 'tool_calls') and last_message.tool_calls:
            return "continue"
        
        return "end"
    
    def run(self, task: str, max_steps: int = 10) -> Dict[str, Any]:
        """è¿è¡Œä»»åŠ¡"""
        print(f"å¼€å§‹æ‰§è¡Œä»»åŠ¡: {task}")
        
        # åˆå§‹åŒ–çŠ¶æ€
        initial_state: AgentState = {
            "messages": [HumanMessage(content=task)],
            "current_step": 0,
            "max_steps": max_steps,
            "task_completed": False,
            "shell_history": [],
            "api_calls": []
        }
        
        # è¿è¡Œå·¥ä½œæµ
        final_state = self.graph.invoke(initial_state)
        
        # æ£€æŸ¥ä»»åŠ¡æ˜¯å¦å®Œæˆ
        last_message = final_state["messages"][-1]
        task_completed = False
        if hasattr(last_message, 'content') and last_message.content:
            task_completed = "FINISHED:" in last_message.content
        
        # è¿”å›ç»“æœ
        return {
            'task': task,
            'completed': task_completed,
            'steps': final_state["current_step"],
            'shell_history': final_state["shell_history"],
            'api_calls': final_state["api_calls"],
            'messages': final_state["messages"]
        }

# ä½¿ç”¨ç¤ºä¾‹
def main():
    """ä¸»å‡½æ•° - æ¼”ç¤ºç”¨æ³•"""
    
    print("=== LangGraph ReAct Shellæ‰§è¡Œå™¨æ¼”ç¤º ===\n")
    
    # åˆ›å»ºä»£ç†
    agent = ReActShellAgent()
    
    # ç¤ºä¾‹ä»»åŠ¡
    tasks = [
        "è·å–ç³»ç»Ÿä¿¡æ¯",
        "åˆ—å‡ºå½“å‰ç›®å½•çš„æ–‡ä»¶",
        "æœç´¢Pythonç›¸å…³çš„GitHubä»“åº“",
        "è·å–åŒ—äº¬çš„å¤©æ°”ä¿¡æ¯"
    ]
    
    for i, task in enumerate(tasks, 1):
        print(f"\n{'='*60}")
        print(f"ä»»åŠ¡ {i}: {task}")
        print(f"{'='*60}")
        
        try:
            result = agent.run(task, max_steps=5)
            
            print(f"\nğŸ“Š æ‰§è¡Œç»“æœ:")
            print(f"  - ä»»åŠ¡å®Œæˆ: {result['completed']}")
            print(f"  - æ‰§è¡Œæ­¥æ•°: {result['steps']}")
            print(f"  - Shellå‘½ä»¤: {len(result['shell_history'])}")
            print(f"  - APIè°ƒç”¨: {len(result['api_calls'])}")
            
            if result['shell_history']:
                print(f"\nğŸ”§ Shellå‘½ä»¤å†å²:")
                for cmd in result['shell_history']:
                    print(f"  â€¢ {cmd['command']}")
            
            if result['api_calls']:
                print(f"\nğŸŒ APIè°ƒç”¨å†å²:")
                for call in result['api_calls']:
                    print(f"  â€¢ {call['tool']}")
                    
        except Exception as e:
            print(f"âŒ ä»»åŠ¡æ‰§è¡Œé”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
        
        print(f"\n{'='*60}")
        
        # å¦‚æœä¸æ˜¯æœ€åä¸€ä¸ªä»»åŠ¡ï¼Œç­‰å¾…ç”¨æˆ·è¾“å…¥
        if i < len(tasks):
            input("æŒ‰å›è½¦ç»§ç»­ä¸‹ä¸€ä¸ªä»»åŠ¡...")

if __name__ == "__main__":
    # æ£€æŸ¥æ˜¯å¦æœ‰OpenAI APIå¯†é’¥
    #if OPENAI_API_KEY == "your-openai-api-key":
    #    print("âš ï¸  è¯·å…ˆè®¾ç½®OPENAI_API_KEY")
    #    print("å¯ä»¥é€šè¿‡ç¯å¢ƒå˜é‡æˆ–ç›´æ¥ä¿®æ”¹ä»£ç ä¸­çš„OPENAI_API_KEYå˜é‡")
    #    exit(1)
    
    main()

